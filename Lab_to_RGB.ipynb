{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab to RGB.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd3Nl5c_rMNd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "from skimage.color import lab2rgb, rgb2lab, rgb2gray\n",
        "from datetime import datetime\n",
        "from torch.autograd import Variable\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary as summary_\n",
        "from tqdm import tqdm\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\\\n",
        "# Accessing My Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4-g3XbucrRoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle  \n",
        "from google.colab import files  \n",
        "files.upload() "
      ],
      "metadata": {
        "id": "sXLO4Z1QrSyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle  \n",
        "!cp kaggle.json ~/.kaggle/    \n",
        "!chmod 600 ~/.kaggle/kaggle.json "
      ],
      "metadata": {
        "id": "na2N2GSSrUFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dataset 다운로드"
      ],
      "metadata": {
        "id": "M_rLbKfnsndM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d aayush9753/image-colorization-dataset"
      ],
      "metadata": {
        "id": "mg24pam9rWDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip image-colorization-dataset.zip  "
      ],
      "metadata": {
        "id": "fwe47W27rXc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Custom Dataset 만들기"
      ],
      "metadata": {
        "id": "mFKmLLjPssGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "class ColorDataSet(Dataset):\n",
        "    def __init__(self, idx_set):\n",
        "        self.gray_path = '/content/data/train_black'\n",
        "        self.color_path = '/content/data/train_color'\n",
        "        self.gray_files = os.listdir(self.gray_path)\n",
        "        self.color_files = os.listdir(self.color_path)\n",
        "    def __len__(self):\n",
        "        return len(self.gray_files)\n",
        "    \n",
        "    def __getitem__(self, idx):        \n",
        "        im = Image.open(self.color_path+'/'+ self.color_files[idx]).convert('RGB')\n",
        "        im = im.resize((256,256))\n",
        "        im = np.array(im)\n",
        "        lab = rgb2lab(im).astype(np.float32)\n",
        "        lab_t = transforms.ToTensor()(lab)\n",
        "        img_l = lab_t[[0], ...] / 50.0 - 1.0\n",
        "        img_ab = lab_t[[1, 2], ...] / 110\n",
        "\n",
        "        img_color = cv2.imread(self.color_path+'/'+ self.color_files[idx])\n",
        "        img_color = cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB)\n",
        "        img_color = cv2.resize(img_color, (256, 256))\n",
        "        img_color = np.transpose(img_color, (2, 0, 1))\n",
        "\n",
        "        img_gray = cv2.imread(self.gray_path+'/'+ self.gray_files[idx])\n",
        "        img_gray = cv2.cvtColor(img_gray, cv2.COLOR_BGR2RGB)\n",
        "        img_gray = cv2.resize(img_gray, (256, 256))\n",
        "        img_gray = np.transpose(img_gray, (2, 0, 1))\n",
        "\n",
        "\n",
        "        img_color = img_color.astype('float32') \n",
        "        img_gray = img_gray.astype('float32') \n",
        "        img_gray = img_gray / 255.\n",
        "        img_color = img_color / 255.\n",
        "        \n",
        "        return img_l, img_ab, img_gray, img_color"
      ],
      "metadata": {
        "id": "c-L8DtzTrYvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_list = list(np.arange(1000))\n",
        "train_val_split = 0.2\n",
        "np.random.seed(0)\n",
        "idx_split = int(train_val_split*1000)\n",
        "np.random.shuffle(idx_list)\n",
        "train_idx = idx_list[idx_split:1000]\n",
        "val_idx = idx_list[:idx_split]\n",
        "\n",
        "train_set = ColorDataSet(idx_set=train_idx)\n",
        "valid_set = ColorDataSet(idx_set=val_idx)\n",
        "\n",
        "train_loader = DataLoader(train_set , batch_size=32 , shuffle=False )\n",
        "valid_loader = DataLoader(valid_set , batch_size=32 , shuffle=False)"
      ],
      "metadata": {
        "id": "1DV1D_sFrc6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = next(iter(train_loader))\n",
        "test_data = next(iter(valid_loader))"
      ],
      "metadata": {
        "id": "3RDXEgEyregS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.max(train_data[0]))\n",
        "print(torch.min(train_data[0]))\n",
        "print(torch.max(train_data[1]))\n",
        "print(torch.min(train_data[1]))\n",
        "print(train_data[0].shape)\n",
        "print(train_data[1].shape)"
      ],
      "metadata": {
        "id": "MOUIcr_vrf6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Generator & Discriminator"
      ],
      "metadata": {
        "id": "nGUpQplIswFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # --------- Encoder ---------\n",
        "        self.encod1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=4, padding=1, stride=2),\n",
        "        )\n",
        "        self.encod2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, padding=1, stride=2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(negative_slope=0.2)\n",
        "        )\n",
        "        self.encod3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, padding=1, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(negative_slope=0.2)\n",
        "        )\n",
        "        self.encod4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, padding=1, stride=2),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(negative_slope=0.2)\n",
        "        )\n",
        "        self.encod5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4, padding=1, stride=2),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(negative_slope=0.2)\n",
        "        )\n",
        "        self.encod6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4, padding=1, stride=2),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "            nn.BatchNorm2d(512),\n",
        "        )\n",
        "        self.encod7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4, padding=1, stride=2),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(negative_slope=0.2)\n",
        "        )\n",
        "        self.encod8 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4, padding=1, stride=2),\n",
        "        )\n",
        "\n",
        "        # --------- Decoder ---------\n",
        "        self.decod8 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=4, padding=1, stride=2),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.Dropout2d(0.5),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decod7 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=2 * 512, out_channels=512, kernel_size=4, padding=1, stride=2),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.Dropout2d(0.5),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decod6 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=2 * 512, out_channels=512, kernel_size=4, padding=1, stride=2),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.Dropout2d(0.5),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decod5 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=2 * 512, out_channels=512, kernel_size=4, padding=1, stride=2),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decod4 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=2 * 512, out_channels=256, kernel_size=4, padding=1, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decod3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=2 * 256, out_channels=128, kernel_size=4, padding=1, stride=2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decod2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=2 * 128, out_channels=64, kernel_size=4, padding=1, stride=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decodout = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=2 * 64, out_channels=2, kernel_size=4, padding=1, stride=2),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        # --------- Encoder ---------\n",
        "        e1 = self.encod1(x)\n",
        "        e2 = self.encod2(e1)\n",
        "        e3 = self.encod3(e2)\n",
        "        e4 = self.encod4(e3)\n",
        "        e5 = self.encod5(e4)\n",
        "        e6 = self.encod6(e5)\n",
        "        e7 = self.encod7(e6)\n",
        "        e8 = self.encod8(e7)\n",
        "\n",
        "        # --------- Decoder ---------\n",
        "        d8 = self.decod8(e8)\n",
        "        d7 = self.decod7(torch.cat([d8, e7], 1))  \n",
        "        d6 = self.decod6(torch.cat([d7, e6], 1))  \n",
        "        d5 = self.decod5(torch.cat([d6, e5], 1))  \n",
        "        d4 = self.decod4(torch.cat([d5, e4], 1))  \n",
        "        d3 = self.decod3(torch.cat([d4, e3], 1))  \n",
        "        d2 = self.decod2(torch.cat([d3, e2], 1))  \n",
        "\n",
        "        out = self.decodout(torch.cat([d2, e1], 1))\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "8eag8OyPrhLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.image_size = 256\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            # input = bs x 256 x 256 x 3 / output = bs x 128 x 128 x 64\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1, stride=2),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "\n",
        "            # input = bs x 128 x 128 x 64 / output = bs x 64 x 64 x 128\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "            \n",
        "            # input = bs x 64 x 64 x 128 / output = bs x 32 x 32 x 256\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "\n",
        "            # input = bs x 32 x 32 x 256 / output = bs x 16 x 16 x 512\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1, stride=2),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "            \n",
        "            # input = bs x 16 x 16 x 512 / output = bs x 8 x 8 x 1\n",
        "            nn.Conv2d(in_channels=512, out_channels=1, kernel_size=3, padding=1, stride=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, clr: torch.Tensor, bw: torch.Tensor):\n",
        "\n",
        "        cat_clr_bw = torch.cat((clr, bw), 1)\n",
        "        features = self.conv(cat_clr_bw)\n",
        "        output = torch.sigmoid(features)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "hw2InsK4rqEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###모델"
      ],
      "metadata": {
        "id": "lTohugWDs0YK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Generator().to(device)\n",
        "summary_(model,(1,256,256),batch_size=1)"
      ],
      "metadata": {
        "id": "yk2ophM2rtTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Discriminator().to(device)\n",
        "summary_(model,[(3,256,256),(3,256,256)],batch_size=1)"
      ],
      "metadata": {
        "id": "CrbTB595ruvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "pAb12bG-rw8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G=Generator().to(device)\n",
        "D=Discriminator().to(device)"
      ],
      "metadata": {
        "id": "h9MdLUa8rynj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###시각화"
      ],
      "metadata": {
        "id": "cjWXesR2s2aT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.color import lab2rgb, rgb2lab, rgb2gray\n",
        "def Lab2Rgb(L, AB):\n",
        "        \"\"\"Convert an Lab tensor image to a RGB numpy output\n",
        "        Parameters:\n",
        "            L  (1-channel tensor array): L channel images (range: [-1, 1], torch tensor array)\n",
        "            AB (2-channel tensor array):  ab channel images (range: [-1, 1], torch tensor array)\n",
        "        Returns:\n",
        "            rgb (RGB numpy image): rgb output images  (range: [0, 255], numpy array)\n",
        "        \"\"\"\n",
        "        AB2 = AB * 110.0\n",
        "        L2 = (L + 1.0) * 50.0\n",
        "        Lab = torch.cat([L2, AB2], dim=0)\n",
        "        Lab = Lab.detach().cpu().float().numpy()\n",
        "        Lab = np.transpose(Lab.astype(np.float64), (1,2,0))\n",
        "        rgb = lab2rgb(Lab) \n",
        "        return rgb"
      ],
      "metadata": {
        "id": "9kRQzlCTsLVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(model, test_input, tar, test_gray,test_rgb):\n",
        "  test_input.to(device)\n",
        "  prediction = model(test_input)\n",
        "  predict = Lab2Rgb(test_input[0],prediction[0])\n",
        "  test_gray = test_gray.cpu().detach().numpy()\n",
        "  test_gray = test_gray.transpose((0,2,3,1))\n",
        "  test_rgb = test_rgb.cpu().detach().numpy()\n",
        "  test_rgb = test_rgb.transpose((0,2,3,1))\n",
        "  display_list = [test_gray[0], test_rgb[0], predict]\n",
        "  title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
        "\n",
        "  plt.figure(figsize=(15,15))\n",
        "  for i in range(3):\n",
        "      plt.subplot(1, 3, i+1)\n",
        "      plt.title(title[i])\n",
        "      plt.imshow((display_list[i]))\n",
        "      plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "l_img = test_data[0]\n",
        "ab_img = test_data[1]\n",
        "gray_img = test_data[2]\n",
        "rgb_img = test_data[3]\n",
        "generate_images(G,l_img.to(device),ab_img.to(device),gray_img.to(device),rgb_img.to(device))"
      ],
      "metadata": {
        "id": "9T4X5OfnsONA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training"
      ],
      "metadata": {
        "id": "eAJgqw11s6ds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch,gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "lr=2e-4\n",
        "betas=(0.5,0.999)\n",
        "g_loss=[]   # storing Generator loss\n",
        "d_loss=[]   # storing Discriminator loss\n",
        "g_epoch_loss=[]\n",
        "d_epoch_loss=[]\n",
        "Epochs = 150\n",
        "\n",
        "SAVEPATH = '/content/drive/MyDrive/Colab Notebooks/pix2pix/'\n",
        "print(os.path.isfile(SAVEPATH + 'model.pth'))"
      ],
      "metadata": {
        "id": "B0JIgs-6sQCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_optimizer=optim.Adam(G.parameters(),lr=lr,betas=betas)\n",
        "d_optimizer=optim.Adam(D.parameters(),lr=lr,betas=betas)\n",
        "\n",
        "checkpoint = torch.load(SAVEPATH + 'pix2pix(6).pth')\n",
        "G.load_state_dict(checkpoint['G_state_dict'])\n",
        "D.load_state_dict(checkpoint['D_state_dict'])\n",
        "g_optimizer.load_state_dict(checkpoint['g_optimizer_state_dict'])\n",
        "d_optimizer.load_state_dict(checkpoint['d_optimizer_state_dict'])\n",
        "\n",
        "criteria = nn.BCEWithLogitsLoss()\n",
        "criteriaL1 = torch.nn.L1Loss()\n",
        "lambda_L1 = 100.0\n",
        "\n",
        "model.train()\n",
        "\n",
        "for i in range(Epochs):\n",
        "    t1=datetime.now()\n",
        "    discriminator_running_loss = 0.0\n",
        "    generator_running_loss = 0.0\n",
        "    size = 0\n",
        "\n",
        "    for ix, data in enumerate(train_loader):\n",
        "        gray_img = data[0].to(device)\n",
        "        rgb_img = data[1].to(device)\n",
        "\n",
        "        batch_size = rgb_img.size(0)\n",
        "        size += batch_size\n",
        "\n",
        "        ## Discriminator train \n",
        "        D.zero_grad()\n",
        "        #real_loss\n",
        "        out=D(rgb_img,gray_img)\n",
        "        real_loss=criteria(out,Variable(torch.ones_like(out)))\n",
        "        #fake_loss\n",
        "        fake_images=G(gray_img).detach()\n",
        "        fake_out=D(fake_images,gray_img)\n",
        "        fake_loss=criteria(fake_out,Variable(torch.zeros_like(fake_out)))\n",
        "\n",
        "        loss_D = (real_loss + fake_loss) * 0.5\n",
        "\n",
        "        discriminator_running_loss += loss_D.item()#.cpu().detach().numpy()\n",
        "\n",
        "        loss_D.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        G.zero_grad()\n",
        "        result=D(G(gray_img),gray_img)\n",
        "        GAN_loss=criteria(result,Variable(torch.ones_like(result)))\n",
        "        L1_loss = criteriaL1(G(gray_img),rgb_img) * lambda_L1\n",
        "\n",
        "        loss_G = GAN_loss + L1_loss\n",
        "\n",
        "        generator_running_loss += loss_G.cpu().detach().numpy()\n",
        "        loss_G.backward()\n",
        "        g_optimizer.step()\n",
        "    epoch_dis_loss = discriminator_running_loss / size\n",
        "    epoch_gen_loss = generator_running_loss / size\n",
        "\n",
        "    d_loss.append(epoch_dis_loss)\n",
        "    g_loss.append(epoch_gen_loss)\n",
        "    print(\"===> Epoch[{}]({}/{}): Loss_D: {:.4f} Loss_G: {:.4f}\".format(\n",
        "            i, ix, len(train_loader), d_loss[i], g_loss[i]))\n",
        "    generate_images(G,test_data[0].to(device),test_data[1].to(device),test_data[2].to(device),test_data[3].to(device))\n",
        "    if(i+1) % 10 == 0:\n",
        "      torch.save({'epoch':i,\n",
        "                  'G_state_dict': G.state_dict(),\n",
        "                  'D_state_dict': D.state_dict(),\n",
        "                  'g_optimizer_state_dict':g_optimizer.state_dict(),\n",
        "                  'd_optimizer_state_dict':d_optimizer.state_dict()},SAVEPATH + 'pix2pix(6).pth')\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "plt.plot(g_loss)\n",
        "plt.plot(d_loss)\n",
        "plt.legend([\"Generator\",\"Discriminator\"])"
      ],
      "metadata": {
        "id": "det6KRmvsXJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###영상 품질 평가 지표"
      ],
      "metadata": {
        "id": "_LYgefuJs9Hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def PSNR(gray,color):\n",
        "  gray = torch.Tensor(gray)\n",
        "  color = torch.Tensor(color)\n",
        "  mse = torch.mean((gray-color)**2)\n",
        "  return 20 * torch.log10(255.0 / torch.sqrt(mse))\n",
        "\n",
        "def SSIM(y_true , y_pred):\n",
        "    u_true = np.mean(y_true)\n",
        "    u_pred = np.mean(y_pred)\n",
        "    var_true = np.var(y_true)\n",
        "    var_pred = np.var(y_pred)\n",
        "    std_true = np.sqrt(var_true)\n",
        "    std_pred = np.sqrt(var_pred)\n",
        "    c1 = np.square(0.01*7)\n",
        "    c2 = np.square(0.03*7)\n",
        "    ssim = (2 * u_true * u_pred + c1) * (2 * std_pred * std_true + c2)\n",
        "    denom = (u_true ** 2 + u_pred ** 2 + c1) * (var_pred + var_true + c2)\n",
        "    return ssim / denom"
      ],
      "metadata": {
        "id": "hC9meVnOsa-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Test"
      ],
      "metadata": {
        "id": "xsMcx4WstCiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(model, test_input, tar, test_gray,test_rgb):\n",
        "  test_input.to(device)\n",
        "  prediction = model(test_input)\n",
        "  predict = []\n",
        "  for i in range(len(test_input)):\n",
        "    predict.append(Lab2Rgb(test_input[i],prediction[i]))\n",
        "  test_gray = test_gray.cpu().detach().numpy()\n",
        "  test_gray = test_gray.transpose((0,2,3,1))\n",
        "  test_rgb = test_rgb.cpu().detach().numpy()\n",
        "  test_rgb = test_rgb.transpose((0,2,3,1))\n",
        "  display_list = [test_gray, test_rgb, predict]\n",
        "  title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
        "  \n",
        "\n",
        "  for i in range(len(test_input)):\n",
        "    ssim = SSIM(test_rgb[i],predict[i])\n",
        "    psnr = PSNR(test_rgb[i],predict[i]).detach().cpu().numpy()\n",
        "    print(\"ssim: \",ssim,\"psnr = \",psnr)\n",
        "    plt.figure(figsize = (20, 20))\n",
        "        \n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(test_gray[i])\n",
        "    plt.title('BandW Image',fontsize = 20)\n",
        "    plt.axis('off')\n",
        "        \n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(predict[i])\n",
        "    plt.title('GenerateImg',fontsize = 20)\n",
        "    plt.axis('off')\n",
        "        \n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(test_rgb[i])\n",
        "    plt.title('Colored Img',fontsize = 20)\n",
        "    plt.axis('off')\n",
        "        \n",
        "  plt.show()\n",
        "\n",
        "\n",
        "checkpoint = torch.load(SAVEPATH + 'pix2pix(6).pth')\n",
        "G.load_state_dict(checkpoint['G_state_dict'])\n",
        "\n",
        "l_img = test_data[0]\n",
        "ab_img = test_data[1]\n",
        "gray_img = test_data[2]\n",
        "rgb_img = test_data[3]\n",
        "generate_images(G,l_img.to(device),ab_img.to(device),gray_img.to(device),rgb_img.to(device))"
      ],
      "metadata": {
        "id": "EpHPAE62sdkj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}